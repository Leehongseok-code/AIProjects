import torch
import torchvision
import matplotlib.pyplot as plt
import numpy
from torchvision import datasets,transforms
import random
from PIL import ImageGrab
import Imagecapture as im
import threading
import time
import pyautogui
import operator

batch_size=1000
device="cpu"
#그리드 버전의 가시화 함수
def imshow_grid(img):
    img = torchvision.utils.make_grid(img.cpu().detach())
    img = (img+1)/2
    npimg = img.numpy()
    plt.imshow(numpy.transpose(npimg, (1,2,0)))
    plt.show()

#이미지를 캡처하는 함수
def Scapture():
    screen = ImageGrab.grab()
    gscreen=screen
    screen = numpy.array(screen)
    #plt.imshow(screen)
    #plt.show()

global gscreen
Scapture()
t_path='./Custom./train_data'
v_path='./Custom./test_data'
#크기 변환
transformed=transforms.Compose([transforms.Resize((28,28)),transforms.Grayscale(1),\
                                transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])

#커스텀 데이터셋을 훈련 데이터로 로딩
custom_train=datasets.ImageFolder(root=t_path,transform=transformed)
custom_test=datasets.ImageFolder(root=v_path,transform=transformed)#나중에 v_path로 변경 요망


data_loader=torch.utils.data.DataLoader(dataset=custom_train,batch_size=batch_size,shuffle=True)
test_loader=torch.utils.data.DataLoader(dataset=custom_test,batch_size=batch_size,shuffle=True)
#훈련 세팅
obstacles=['ground','bird','cactus']
device=torch.device("cpu")
linear=torch.nn.Linear(784,10,bias=True).to(device)
loss=torch.nn.CrossEntropyLoss().to(device)
SDG=torch.optim.SGD(linear.parameters(),lr=0.01)

total_batch=len(data_loader)#60=60000/1000(total/batch_size)
training_epochs=150


'''''
#이미지분할
for w in range(10):
    for h in range(30):
        bbox=(h*grid_h, w*grid_w,(h+1)*grid_h,(w+1)*grid_w)
        crop_img=img.crop(bbox)
        fname="{}.jpg".format("{0:05d}".format(i))
        savename="./Custom./Captured_data./Captured"+fname
        crop_img.save(savename)
        i+=1
'''''
#이미지 가져오기
image, label=custom_train[0]
'''''
#이미지 보여주기
plt.imshow(image.squeeze().numpy(), cmap='gray')

plt.show()
'''''

#정답 확인

#훈련 시작
for epoch in range(training_epochs):
    total_cost=0

    for X, Y in data_loader:
        X=X.view(-1,28*28).to(device)
        Y=Y.to(device)

        hypothesis=linear(X)
        cost=loss(hypothesis, Y)

        SDG.zero_grad()
        cost.backward()
        SDG.step()

        total_cost+=cost

    avg_cost=total_cost/total_batch
    print("Epoch:","%03d"%(epoch+1),"cost=","{:.9f}".format(avg_cost))


lock=threading.Lock()
def cutandread():
    j=0
    t=0
    try:
        while(True):
            #이미지 일부분만 가져오기
            img=ImageGrab.grab()
            (img_h,img_w)=img.size
            grid_w=66#cut할 너비
            grid_h=50#cut할 높이
            range_w=(int)(img_w/grid_w)
            range_h=(int)(img_h/grid_h)
            i=0
            bbox = (14.4* grid_h, 3.8 * grid_w, (14.4+ 1) * grid_h, (3.8+ 1) * grid_w)
            crop_img = img.crop(bbox)#crop_img-추출된 이미지

            #폴더에 임시저장and 덮어쓰기

            #정답 가시화
            with torch.no_grad():
                for data,target in test_loader:

                    #X_test = custom_test.data.view(-1, 28 * 28).float().to(device)
                    X_test=data.view(-1,28*28).float().to(device)
                    Y_test =target.float().to(device)
                    prediction = linear(X_test)
                    correct_prediction = torch.argmax(prediction, 1) == Y_test
                    accuracy = correct_prediction.float().mean()




            #vis_loader=torch.utils.data.DataLoader(custom_test,16,True)
            #img_ans, label_ans=next(iter(vis_loader))

            #imshow_grid(img_ans)

            #이미지 크기 재조정후 화면 캡처된 이미지가 무엇인지 판별
            #label_predicted=linear(img_ans.to(device).view(-1, 28 * 28).float().to(device))
            #plt.imshow(crop_img)#-쓰레드에서는 matplotlib 사용 불가능
            #plt.show()
            cimg=transformed(crop_img)


            label_predicted=linear(cimg.to(device).view(-1, 28 * 28).float().to(device))
            _, top_i = torch.topk(label_predicted, k=1, dim=-1)
            tempp=top_i.transpose(0,1)[0]
            #tempa=label_ans.view(1,-1).cpu()[0]
            #print('prediction:',top_i.transpose(0,1))
            #print('real:', label_ans.view(1,-1).cpu())
            lock.acquire()
            for i in tempp:
                print(obstacles[int(i)])

                if operator.eq(obstacles[int(i)],'ground')==False:
                    pyautogui.press('space')
                    time.sleep(0.005)
                    pyautogui.press('space')
                    time.sleep(0.005)
                    pyautogui.press('space')
                    time.sleep(0.005)
                    pyautogui.press('space')
                    time.sleep(0.005)
                    pyautogui.press('space')
                    #plt.imshow(crop_img)
                    #plt.show()
                    print("1")

            j+=1
            print(j)
            lock.release()

            #for i in tempa:
            #    print(obstacles[(int(i)+1)%3],end=',')
    except KeyboardInterrupt:
        print("1")
        th1.wait()

th1=threading.Thread(target=cutandread)
th1.start()
#cutandread()
